{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6xlvUhlFYKDL84h+QZZrc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fenix198811/Fenix198811/blob/main/SimpleNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eR4NOoY4YtPh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Model Class that inherits nn.Module\n",
        "class Model(nn.Module):\n",
        "    # Input layer (4 features of the flower) -> hidden layer1(num of neural) -> hidden layer2(num of neural) -> output(3 types of the flower)\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "        super().__init__() # instantiate the nn module\n",
        "        self.fc1 = nn.Linear(in_features, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.out = nn.Linear(h2, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.out(x)\n",
        "      return x\n"
      ],
      "metadata": {
        "id": "2qr7CYEFaIcO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a manual seed for randomization\n",
        "torch.manual_seed(68)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "BZ0Lx0z1fIxl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "yvihxHm8fzak"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\"\n",
        "my_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "_OI7Hi1Pf-kl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df[\"variety\"] = my_df['variety'].replace(\"Setosa\", 0)\n",
        "my_df[\"variety\"] = my_df['variety'].replace(\"Versicolor\", 1)\n",
        "my_df[\"variety\"] = my_df['variety'].replace(\"Virginica\", 2)"
      ],
      "metadata": {
        "id": "BGiigmHPgP9q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = my_df.drop(\"variety\", axis=1)\n",
        "y = my_df[\"variety\"]"
      ],
      "metadata": {
        "id": "5JQMSgo6gutx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.values\n",
        "y = y.values"
      ],
      "metadata": {
        "id": "89aWMj2Fg-kv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "nDjb0Uq3hIej"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=68)"
      ],
      "metadata": {
        "id": "n1XVGm76hSN0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "4rb4XsP1hvbZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the criterion of model to measure the error, how fa off the predications are from\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Choose Adam Optimizer and learn rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "bVJshJgSiMcO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train our model\n",
        "# Epochs\n",
        "epochs = 100\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "    # Go forward and get a prediction\n",
        "    y_pred = model.forward(X_train) # Get predicted results\n",
        "\n",
        "    # Measure the loss/error,\n",
        "    loss = criterion(y_pred, y_train) # predicated values vs the y_train\n",
        "\n",
        "    # Keep track of our losses\n",
        "    losses.append(loss.detach().numpy())\n",
        "\n",
        "    # Print the epoch every loop run\n",
        "    print(f\"Epoch {i} and loss: {loss}\")\n",
        "\n",
        "    # Do some back propagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64UdIAG6j3nQ",
        "outputId": "a442fea7-4da6-4c03-875d-ceef1bb6cf0b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 and loss: 1.0988285541534424\n",
            "Epoch 1 and loss: 1.0394829511642456\n",
            "Epoch 2 and loss: 1.0114531517028809\n",
            "Epoch 3 and loss: 0.9953886270523071\n",
            "Epoch 4 and loss: 0.9801366925239563\n",
            "Epoch 5 and loss: 0.9641412496566772\n",
            "Epoch 6 and loss: 0.9458622336387634\n",
            "Epoch 7 and loss: 0.9253131151199341\n",
            "Epoch 8 and loss: 0.9024745225906372\n",
            "Epoch 9 and loss: 0.8770564198493958\n",
            "Epoch 10 and loss: 0.8500342965126038\n",
            "Epoch 11 and loss: 0.8216476440429688\n",
            "Epoch 12 and loss: 0.7921905517578125\n",
            "Epoch 13 and loss: 0.7656181454658508\n",
            "Epoch 14 and loss: 0.7416889071464539\n",
            "Epoch 15 and loss: 0.7177014350891113\n",
            "Epoch 16 and loss: 0.6916178464889526\n",
            "Epoch 17 and loss: 0.664244532585144\n",
            "Epoch 18 and loss: 0.6389275789260864\n",
            "Epoch 19 and loss: 0.617169976234436\n",
            "Epoch 20 and loss: 0.5969469547271729\n",
            "Epoch 21 and loss: 0.5762972235679626\n",
            "Epoch 22 and loss: 0.5555516481399536\n",
            "Epoch 23 and loss: 0.5358654856681824\n",
            "Epoch 24 and loss: 0.5175567865371704\n",
            "Epoch 25 and loss: 0.500082790851593\n",
            "Epoch 26 and loss: 0.482612282037735\n",
            "Epoch 27 and loss: 0.4658830463886261\n",
            "Epoch 28 and loss: 0.45056843757629395\n",
            "Epoch 29 and loss: 0.4360555410385132\n",
            "Epoch 30 and loss: 0.42094773054122925\n",
            "Epoch 31 and loss: 0.40535202622413635\n",
            "Epoch 32 and loss: 0.39063921570777893\n",
            "Epoch 33 and loss: 0.3770321309566498\n",
            "Epoch 34 and loss: 0.3630354404449463\n",
            "Epoch 35 and loss: 0.3483351171016693\n",
            "Epoch 36 and loss: 0.3344030976295471\n",
            "Epoch 37 and loss: 0.32124581933021545\n",
            "Epoch 38 and loss: 0.30738720297813416\n",
            "Epoch 39 and loss: 0.29345741868019104\n",
            "Epoch 40 and loss: 0.2806602716445923\n",
            "Epoch 41 and loss: 0.2676399052143097\n",
            "Epoch 42 and loss: 0.2543724775314331\n",
            "Epoch 43 and loss: 0.24226944148540497\n",
            "Epoch 44 and loss: 0.23011764883995056\n",
            "Epoch 45 and loss: 0.21824193000793457\n",
            "Epoch 46 and loss: 0.20746739208698273\n",
            "Epoch 47 and loss: 0.19650298357009888\n",
            "Epoch 48 and loss: 0.18639470636844635\n",
            "Epoch 49 and loss: 0.1768588423728943\n",
            "Epoch 50 and loss: 0.16755184531211853\n",
            "Epoch 51 and loss: 0.15934012830257416\n",
            "Epoch 52 and loss: 0.1512008160352707\n",
            "Epoch 53 and loss: 0.14405198395252228\n",
            "Epoch 54 and loss: 0.13727986812591553\n",
            "Epoch 55 and loss: 0.13107970356941223\n",
            "Epoch 56 and loss: 0.12547580897808075\n",
            "Epoch 57 and loss: 0.12015969306230545\n",
            "Epoch 58 and loss: 0.11551599204540253\n",
            "Epoch 59 and loss: 0.11105045676231384\n",
            "Epoch 60 and loss: 0.10719157010316849\n",
            "Epoch 61 and loss: 0.10344786942005157\n",
            "Epoch 62 and loss: 0.1002231240272522\n",
            "Epoch 63 and loss: 0.09711218625307083\n",
            "Epoch 64 and loss: 0.0943918228149414\n",
            "Epoch 65 and loss: 0.09178844839334488\n",
            "Epoch 66 and loss: 0.08950342237949371\n",
            "Epoch 67 and loss: 0.08732427656650543\n",
            "Epoch 68 and loss: 0.08538161963224411\n",
            "Epoch 69 and loss: 0.08352333307266235\n",
            "Epoch 70 and loss: 0.08184996247291565\n",
            "Epoch 71 and loss: 0.08025000244379044\n",
            "Epoch 72 and loss: 0.07880496978759766\n",
            "Epoch 73 and loss: 0.07741831988096237\n",
            "Epoch 74 and loss: 0.07616264373064041\n",
            "Epoch 75 and loss: 0.07495182007551193\n",
            "Epoch 76 and loss: 0.07385876774787903\n",
            "Epoch 77 and loss: 0.07279586791992188\n",
            "Epoch 78 and loss: 0.07183990627527237\n",
            "Epoch 79 and loss: 0.07090233266353607\n",
            "Epoch 80 and loss: 0.07005809992551804\n",
            "Epoch 81 and loss: 0.06923093646764755\n",
            "Epoch 82 and loss: 0.06848029047250748\n",
            "Epoch 83 and loss: 0.0677509605884552\n",
            "Epoch 84 and loss: 0.06707780063152313\n",
            "Epoch 85 and loss: 0.06643403321504593\n",
            "Epoch 86 and loss: 0.06582577526569366\n",
            "Epoch 87 and loss: 0.06525640189647675\n",
            "Epoch 88 and loss: 0.06470441073179245\n",
            "Epoch 89 and loss: 0.06419426947832108\n",
            "Epoch 90 and loss: 0.06369519233703613\n",
            "Epoch 91 and loss: 0.06323126703500748\n",
            "Epoch 92 and loss: 0.06278093159198761\n",
            "Epoch 93 and loss: 0.06235198676586151\n",
            "Epoch 94 and loss: 0.06194491684436798\n",
            "Epoch 95 and loss: 0.06154908612370491\n",
            "Epoch 96 and loss: 0.061176396906375885\n",
            "Epoch 97 and loss: 0.060813069343566895\n",
            "Epoch 98 and loss: 0.060466889292001724\n",
            "Epoch 99 and loss: 0.060134146362543106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model on Test Data Set\n",
        "with torch.no_grad():\n",
        "    y_eval = model.forward(X_test)\n",
        "    loss = criterion(y_eval, y_test)\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOqXhjp5lqbm",
        "outputId": "9a896247-4e00-4002-e461-0618320f8867"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0577)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_iris = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "with torch.no_grad():\n",
        "    print(model(new_iris))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFzrsFA7mnp7",
        "outputId": "3fa8d672-e781-4472-e3fb-ca7e2818dfef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-10.5935,   3.1792,  19.5386])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our NN model\n",
        "torch.save(model.state_dict(), \"my_iris_flower_model.pt\")"
      ],
      "metadata": {
        "id": "GZ0h9YHOpFsi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the save model\n",
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load(\"my_iris_flower_model.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYFgtXSxpWOb",
        "outputId": "7d39f0f2-eac5-491b-f661-f523a237ff72"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('my_iris_flower_model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8oUtWiM3qIj5",
        "outputId": "abb4aedd-1a22-4a54-dc4c-74a73081c07a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_99a77fe7-2904-438a-bcf8-d4409c96021c\", \"my_iris_flower_model.pt\", 3146)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "HCJJEaLuqR7F",
        "outputId": "08701114-36ad-40b7-d039-304b37819421"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e0b653cc-0f60-48c1-8ca0-bc53bdaf1c53\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e0b653cc-0f60-48c1-8ca0-bc53bdaf1c53\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving my_iris_flower_model.pt to my_iris_flower_model (1).pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'my_iris_flower_model (1).pt': b'PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1d\\x00\\x05\\x00my_iris_flower_model/data.pklFB\\x01\\x00Z\\x80\\x02ccollections\\nOrderedDict\\nq\\x00)Rq\\x01(X\\n\\x00\\x00\\x00fc1.weightq\\x02ctorch._utils\\n_rebuild_tensor_v2\\nq\\x03((X\\x07\\x00\\x00\\x00storageq\\x04ctorch\\nFloatStorage\\nq\\x05X\\x01\\x00\\x00\\x000q\\x06X\\x03\\x00\\x00\\x00cpuq\\x07K tq\\x08QK\\x00K\\x08K\\x04\\x86q\\tK\\x04K\\x01\\x86q\\n\\x89h\\x00)Rq\\x0btq\\x0cRq\\rX\\x08\\x00\\x00\\x00fc1.biasq\\x0eh\\x03((h\\x04h\\x05X\\x01\\x00\\x00\\x001q\\x0fh\\x07K\\x08tq\\x10QK\\x00K\\x08\\x85q\\x11K\\x01\\x85q\\x12\\x89h\\x00)Rq\\x13tq\\x14Rq\\x15X\\n\\x00\\x00\\x00fc2.weightq\\x16h\\x03((h\\x04h\\x05X\\x01\\x00\\x00\\x002q\\x17h\\x07KHtq\\x18QK\\x00K\\tK\\x08\\x86q\\x19K\\x08K\\x01\\x86q\\x1a\\x89h\\x00)Rq\\x1btq\\x1cRq\\x1dX\\x08\\x00\\x00\\x00fc2.biasq\\x1eh\\x03((h\\x04h\\x05X\\x01\\x00\\x00\\x003q\\x1fh\\x07K\\ttq QK\\x00K\\t\\x85q!K\\x01\\x85q\"\\x89h\\x00)Rq#tq$Rq%X\\n\\x00\\x00\\x00out.weightq&h\\x03((h\\x04h\\x05X\\x01\\x00\\x00\\x004q\\'h\\x07K\\x1btq(QK\\x00K\\x03K\\t\\x86q)K\\tK\\x01\\x86q*\\x89h\\x00)Rq+tq,Rq-X\\x08\\x00\\x00\\x00out.biasq.h\\x03((h\\x04h\\x05X\\x01\\x00\\x00\\x005q/h\\x07K\\x03tq0QK\\x00K\\x03\\x85q1K\\x01\\x85q2\\x89h\\x00)Rq3tq4Rq5u}q6X\\t\\x00\\x00\\x00_metadataq7h\\x00)Rq8(X\\x00\\x00\\x00\\x00q9}q:X\\x07\\x00\\x00\\x00versionq;K\\x01sX\\x03\\x00\\x00\\x00fc1q<}q=h;K\\x01sX\\x03\\x00\\x00\\x00fc2q>}q?h;K\\x01sX\\x03\\x00\\x00\\x00outq@}qAh;K\\x01susb.PK\\x07\\x08\\x1e0KBm\\x02\\x00\\x00m\\x02\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1e\\x00\\x07\\x00my_iris_flower_model/byteorderFB\\x03\\x00ZZZlittlePK\\x07\\x08\\x85=\\xe3\\x19\\x06\\x00\\x00\\x00\\x06\\x00\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1b\\x001\\x00my_iris_flower_model/data/0FB-\\x00ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ\\x08\\xa6\\xce\\xbd _U=\\xb2\\x94\\xcc\\xbep\\xd1\\\\\\xbe<<Z?\\x91{\\xc7>\\x92\\x1cM?\\xdc\\x94\\x02>\\x95\\x96\\xe1\\xbex0\\xca=\\xcb\\x8dF?L\\x90\\x1e?\\xfd\\xc8\\x14?\\x0b\\xca\\x02?\\x06\\xa7\\xd9\\xbe\\x19\\x1b`\\xbf\\xed\\xf4t\\xbd\\xd0I<?\\xc4\\xb2v<\\x0e\\xb9[\\xbf\\xde}\\x91=^\\xc9\\xf1\\xbe\\xfc\\x00E?|\\xed\\xf7>\\xee\\x1a\\xea\\xbe\\x80\\xafu\\xbd\\x94\\x14\\x86\\xbe\\x00\\xffX\\xbbe\\xb7\\x8d>x\\xe5\\xda\\xbd\\xfa^\\x82\\xbd\\x8f\\xb3\\xc5\\xbePK\\x07\\x08\\xcdt\\x95\\xc9\\x80\\x00\\x00\\x00\\x80\\x00\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1b\\x007\\x00my_iris_flower_model/data/1FB3\\x00ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ\\x00\\x82\\xa0=|\\xac`\\xbe\\xa6\\xd5f\\xbfz\\xdf1?+\\x90\\x07>\\x98\\xdf*\\xbe&Z\\xe5>+\\xec\\r\\xbePK\\x07\\x08\\x02\\x11M\\xa5 \\x00\\x00\\x00 \\x00\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1b\\x00\\x17\\x00my_iris_flower_model/data/2FB\\x13\\x00ZZZZZZZZZZZZZZZZZZZ\\xc8a\\x86\\xbe!+\\xa9\\xbe(UM>\\xf2s;\\xbe\\xd9\\xcf\\xe3=r\\x10\\xa3=\\xbb\\xd0\\x85\\xbe\\xfbq\\x8c\\xbe\\xfeXB\\xbe\\xf3\\xfc\\x10\\xbe^Q\\xc4\\xbe\\xb0\\xac\\x05\\xbea\\x0bH\\xbeWl\\x8b\\xbe\\x13N\\x9c>\\xc6\\xe5Z>Z\\xec\\xfc\\xbb1&\\xb5=\\xca\\xb7\\x17?q\\xdf\\x86\\xbf\"\\xbbO\\xbf7\\xd9;?\\x16\\x06\\x01\\xbe\\xe9\\x03\\xbb\\xbczQ\\x1b\\xbevt4>\\x0b\\\\)>\\xad\\x84b=/\\xd5*\\xbf\\x19#\\r?\\xdf\\x81\\xb4\\xbd\\x81QF>\\x8a\\xa8\\x0c\\xbe\\xdf\\x0bQ?\\x82\\xd1e\\xbf\\xcd\\x8bs?\\x92R3?\\xe5\\xdc\\xf5\\xbe\\xb3\\x02\\xbd\\xbcV\\xfb\\x9b>\\xbb\\xb3\\xac>\\x15\\xe7B>xX\\x17?\\x1d\\xf3c\\xbeS\\x93+\\xbeEc\\x9a>\\xa9\\xc2\\x9a<\\xacY5=\\\\\\xd9\\x91=\\xd3l\\xea>_P\\x84=q\\r\\xb4\\xbe\\xb0\\xb0\\x06\\xbfh\\xc5\\x1b?\\xc9\\xd8P={t\\xb0\\xbe\\x18\\xfdb>\\xf1)I>\\xe2]\\x83?\\xf2\\xcd\\x12\\xbf\\x7f\\xbd\\x82\\xbf\\xa5\\xad\\xe3>\\xeb\\xe5\\t>\\xd3\\xde\\x9b\\xbe\\x01\\xd1$>\\x00\\x1d\\xc9>\\x9cU\\xf9>\\xa0b\\x87\\xbe\\x9b\\xcf\\x1b\\xbf\\xde1a?\\xd5E\\xef\\xba\\x11I\\xfe\\xbePK\\x07\\x08\\x85_\\xf3\\n \\x01\\x00\\x00 \\x01\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1b\\x00\\x17\\x00my_iris_flower_model/data/3FB\\x13\\x00ZZZZZZZZZZZZZZZZZZZ\\xbb\\x18I\\xbc\\rz\\x01>\\x1a\\xb4\\xae\\xbe\\x12\\xc0\\xc4\\xbd4\\xe3k?`\\xfd\\xf7\\xbe4\\xc5\\x1e\\xbe\\x04\\x89\\x19\\xbfc/X\\xbePK\\x07\\x08\\xea\\x13<\\xab$\\x00\\x00\\x00$\\x00\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1b\\x00\\x13\\x00my_iris_flower_model/data/4FB\\x0f\\x00ZZZZZZZZZZZZZZZ\\xc6Sz\\xbe\\xd7\\xa1\\x8f\\xbd~\\xfb\\x13\\xbf\\xcb;\\xe2\\xbe\\x02:\\xf0>\\xbb\\x1e\\xaf\\xbdb6/\\xbf\\xc2\\x88\\xe0\\xbe[\\x19\\x8f\\xbe\\x0e\\xdf\\x9c>\\xf0d\\xbd\\xbetR\\xc1\\xbe\\xd1\\x0c\\xc6>_\\xe3<=s\\x90\\xc0=\\x86\\xc1\\x14?P\\x82=\\xbe\\x99s\\xb7>\\xde\\xbc4>\\xa6\\xf4f>\\xf1\\x94\\x8c?\\x9fk\\x8b>\\xcb\\xe6n\\xbf\\xf9\\x8d\\xe5>\\x1fy9?\\x1e\\x94}?p\\x19C?PK\\x07\\x08\\x83\\xde;\\xbfl\\x00\\x00\\x00l\\x00\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1b\\x00\\x0b\\x00my_iris_flower_model/data/5FB\\x07\\x00ZZZZZZZF\\\\\\x03?/\\x93\\xdd\\xbd\\x1afH\\xbfPK\\x07\\x08\\xea\\x9b\\x91d\\x0c\\x00\\x00\\x00\\x0c\\x00\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c\\x00*\\x00my_iris_flower_model/versionFB&\\x00ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ3\\nPK\\x07\\x08\\xd1\\x9egU\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00PK\\x03\\x04\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00+\\x00%\\x00my_iris_flower_model/.data/serialization_idFB!\\x00ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ0534327824949796574701147514329843623562PK\\x07\\x08\\xa9h\\x1fP(\\x00\\x00\\x00(\\x00\\x00\\x00PK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x1e0KBm\\x02\\x00\\x00m\\x02\\x00\\x00\\x1d\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00my_iris_flower_model/data.pklPK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x85=\\xe3\\x19\\x06\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xbd\\x02\\x00\\x00my_iris_flower_model/byteorderPK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\xcdt\\x95\\xc9\\x80\\x00\\x00\\x00\\x80\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x03\\x00\\x00my_iris_flower_model/data/0PK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x11M\\xa5 \\x00\\x00\\x00 \\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x04\\x00\\x00my_iris_flower_model/data/1PK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x85_\\xf3\\n \\x01\\x00\\x00 \\x01\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xb0\\x04\\x00\\x00my_iris_flower_model/data/2PK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\xea\\x13<\\xab$\\x00\\x00\\x00$\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x000\\x06\\x00\\x00my_iris_flower_model/data/3PK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x83\\xde;\\xbfl\\x00\\x00\\x00l\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xb4\\x06\\x00\\x00my_iris_flower_model/data/4PK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\xea\\x9b\\x91d\\x0c\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x1b\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x07\\x00\\x00my_iris_flower_model/data/5PK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\xd1\\x9egU\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdc\\x07\\x00\\x00my_iris_flower_model/versionPK\\x01\\x02\\x00\\x00\\x00\\x00\\x08\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\xa9h\\x1fP(\\x00\\x00\\x00(\\x00\\x00\\x00+\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00R\\x08\\x00\\x00my_iris_flower_model/.data/serialization_idPK\\x06\\x06,\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1e\\x03-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf0\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\xf8\\x08\\x00\\x00\\x00\\x00\\x00\\x00PK\\x06\\x07\\x00\\x00\\x00\\x00\\xe8\\x0b\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00PK\\x05\\x06\\x00\\x00\\x00\\x00\\n\\x00\\n\\x00\\xf0\\x02\\x00\\x00\\xf8\\x08\\x00\\x00\\x00\\x00'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}